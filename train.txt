x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 1)
50000 train samples
10000 test samples
D:\software\anaconda\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
D:\software\anaconda\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2024-01-10 00:20:43.464212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-10 00:20:43.876409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5473 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896

 activation (Activation)     (None, 32, 32, 32)        0

 conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248

 activation_1 (Activation)   (None, 30, 30, 32)        0

 max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0
 )

 dropout (Dropout)           (None, 15, 15, 32)        0

 conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496

 activation_2 (Activation)   (None, 15, 15, 64)        0

 conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928

 activation_3 (Activation)   (None, 13, 13, 64)        0

 max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0
 2D)

 dropout_1 (Dropout)         (None, 6, 6, 64)          0

 flatten (Flatten)           (None, 2304)              0

 dense (Dense)               (None, 512)               1180160

 activation_4 (Activation)   (None, 512)               0

 dropout_2 (Dropout)         (None, 512)               0

 dense_1 (Dense)             (None, 10)                5130

 activation_5 (Activation)   (None, 10)                0

=================================================================
Total params: 1,250,858
Trainable params: 1,250,858
Non-trainable params: 0
_________________________________________________________________
未使用数据增强。
2024-01-10 00:20:44.473900: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.
Epoch 1/60
2024-01-10 00:20:45.864121: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8902
2024-01-10 00:20:46.603137: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1563/1563 [==============================] - 12s 6ms/step - loss: 1.7885 - accuracy: 0.3404 - val_loss: 1.4993 - val_accuracy: 0.4480
Epoch 2/60
1563/1563 [==============================] - 9s 6ms/step - loss: 1.4769 - accuracy: 0.4672 - val_loss: 1.3465 - val_accuracy: 0.5195
Epoch 3/60
1563/1563 [==============================] - 9s 6ms/step - loss: 1.3521 - accuracy: 0.5165 - val_loss: 1.2457 - val_accuracy: 0.5530
Epoch 4/60
1563/1563 [==============================] - 9s 6ms/step - loss: 1.2584 - accuracy: 0.5516 - val_loss: 1.1734 - val_accuracy: 0.5778
Epoch 5/60
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1794 - accuracy: 0.5845 - val_loss: 1.1157 - val_accuracy: 0.5989
Epoch 6/60
1563/1563 [==============================] - 9s 6ms/step - loss: 1.1161 - accuracy: 0.6080 - val_loss: 1.0291 - val_accuracy: 0.6375
Epoch 7/60
1563/1563 [==============================] - 9s 6ms/step - loss: 1.0624 - accuracy: 0.6268 - val_loss: 1.0122 - val_accuracy: 0.6436
Epoch 8/60
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0131 - accuracy: 0.6438 - val_loss: 0.9375 - val_accuracy: 0.6718
Epoch 9/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9787 - accuracy: 0.6589 - val_loss: 0.9342 - val_accuracy: 0.6729
Epoch 10/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.9411 - accuracy: 0.6704 - val_loss: 0.8890 - val_accuracy: 0.6868
Epoch 11/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9116 - accuracy: 0.6826 - val_loss: 0.8785 - val_accuracy: 0.6968
Epoch 12/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.8831 - accuracy: 0.6888 - val_loss: 0.8478 - val_accuracy: 0.7079
Epoch 13/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.8618 - accuracy: 0.7012 - val_loss: 0.8726 - val_accuracy: 0.6966
Epoch 14/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.8399 - accuracy: 0.7070 - val_loss: 0.8041 - val_accuracy: 0.7231
Epoch 15/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.8204 - accuracy: 0.7155 - val_loss: 0.8370 - val_accuracy: 0.7066
Epoch 16/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.8045 - accuracy: 0.7188 - val_loss: 0.7660 - val_accuracy: 0.7379
Epoch 17/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7895 - accuracy: 0.7267 - val_loss: 0.7637 - val_accuracy: 0.7365
Epoch 18/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7786 - accuracy: 0.7334 - val_loss: 0.7558 - val_accuracy: 0.7427
Epoch 19/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7687 - accuracy: 0.7362 - val_loss: 0.7883 - val_accuracy: 0.7298
Epoch 20/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7501 - accuracy: 0.7393 - val_loss: 0.7569 - val_accuracy: 0.7422
Epoch 21/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7448 - accuracy: 0.7430 - val_loss: 0.7708 - val_accuracy: 0.7342
Epoch 22/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7384 - accuracy: 0.7449 - val_loss: 0.7229 - val_accuracy: 0.7565
Epoch 23/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7312 - accuracy: 0.7484 - val_loss: 0.7099 - val_accuracy: 0.7611
Epoch 24/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7221 - accuracy: 0.7517 - val_loss: 0.7088 - val_accuracy: 0.7622
Epoch 25/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7186 - accuracy: 0.7539 - val_loss: 0.7249 - val_accuracy: 0.7555
Epoch 26/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7109 - accuracy: 0.7562 - val_loss: 0.7213 - val_accuracy: 0.7583
Epoch 27/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7067 - accuracy: 0.7588 - val_loss: 0.7146 - val_accuracy: 0.7600
Epoch 28/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7056 - accuracy: 0.7608 - val_loss: 0.7154 - val_accuracy: 0.7596
Epoch 29/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7021 - accuracy: 0.7616 - val_loss: 0.6909 - val_accuracy: 0.7701
Epoch 30/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6952 - accuracy: 0.7639 - val_loss: 0.7148 - val_accuracy: 0.7576
Epoch 31/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6905 - accuracy: 0.7662 - val_loss: 0.6969 - val_accuracy: 0.7663
Epoch 32/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6839 - accuracy: 0.7675 - val_loss: 0.6653 - val_accuracy: 0.7757
Epoch 33/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6762 - accuracy: 0.7710 - val_loss: 0.7756 - val_accuracy: 0.7423
Epoch 34/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6851 - accuracy: 0.7681 - val_loss: 0.7151 - val_accuracy: 0.7713
Epoch 35/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6800 - accuracy: 0.7715 - val_loss: 0.6633 - val_accuracy: 0.7773
Epoch 36/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6758 - accuracy: 0.7741 - val_loss: 0.6908 - val_accuracy: 0.7698
Epoch 37/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6715 - accuracy: 0.7741 - val_loss: 0.6693 - val_accuracy: 0.7769
Epoch 38/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6709 - accuracy: 0.7731 - val_loss: 0.6913 - val_accuracy: 0.7767
Epoch 39/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6671 - accuracy: 0.7771 - val_loss: 0.6684 - val_accuracy: 0.7808
Epoch 40/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6646 - accuracy: 0.7770 - val_loss: 0.6634 - val_accuracy: 0.7793
Epoch 41/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6636 - accuracy: 0.7778 - val_loss: 0.6724 - val_accuracy: 0.7780
Epoch 42/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6589 - accuracy: 0.7781 - val_loss: 0.6905 - val_accuracy: 0.7789
Epoch 43/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6593 - accuracy: 0.7796 - val_loss: 0.6545 - val_accuracy: 0.7844
Epoch 44/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6550 - accuracy: 0.7798 - val_loss: 0.6774 - val_accuracy: 0.7746
Epoch 45/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6557 - accuracy: 0.7799 - val_loss: 0.6996 - val_accuracy: 0.7778
Epoch 46/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6526 - accuracy: 0.7819 - val_loss: 0.6679 - val_accuracy: 0.7768
Epoch 47/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6526 - accuracy: 0.7829 - val_loss: 0.6710 - val_accuracy: 0.7751
Epoch 48/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6477 - accuracy: 0.7828 - val_loss: 0.6550 - val_accuracy: 0.7840
Epoch 49/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6462 - accuracy: 0.7846 - val_loss: 0.6868 - val_accuracy: 0.7787
Epoch 50/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6488 - accuracy: 0.7845 - val_loss: 0.6519 - val_accuracy: 0.7834
Epoch 51/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6410 - accuracy: 0.7858 - val_loss: 0.6879 - val_accuracy: 0.7727
Epoch 52/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6446 - accuracy: 0.7848 - val_loss: 0.6409 - val_accuracy: 0.7850
Epoch 53/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6428 - accuracy: 0.7851 - val_loss: 0.6735 - val_accuracy: 0.7819
Epoch 54/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6389 - accuracy: 0.7873 - val_loss: 0.6609 - val_accuracy: 0.7860
Epoch 55/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6383 - accuracy: 0.7871 - val_loss: 0.6833 - val_accuracy: 0.7816
Epoch 56/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6375 - accuracy: 0.7868 - val_loss: 0.6700 - val_accuracy: 0.7829
Epoch 57/60
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6383 - accuracy: 0.7867 - val_loss: 0.6975 - val_accuracy: 0.7750
Epoch 58/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6366 - accuracy: 0.7870 - val_loss: 0.6606 - val_accuracy: 0.7877
Epoch 59/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6329 - accuracy: 0.7909 - val_loss: 0.6903 - val_accuracy: 0.7714
Epoch 60/60
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6344 - accuracy: 0.7895 - val_loss: 0.6632 - val_accuracy: 0.7822
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
313/313 [==============================] - 1s 2ms/step - loss: 0.6632 - accuracy: 0.7822
测试损失: 0.6631759405136108
测试精度: 0.7821999788284302
313/313 [==============================] - 1s 2ms/step
              precision    recall  f1-score   support

           0       0.84      0.76      0.80      1000
           1       0.94      0.85      0.89      1000
           2       0.67      0.69      0.68      1000
           3       0.66      0.56      0.60      1000
           4       0.79      0.71      0.75      1000
           5       0.62      0.79      0.69      1000
           6       0.74      0.89      0.81      1000
           7       0.90      0.78      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.85      0.90      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

1/1 [==============================] - 0s 63ms/step
已在 F:\industry\tb017627868已付250深度\saved_models\keras_cifar10_trained_model.h5 保存训练好的模型
313/313 [==============================] - 1s 3ms/step - loss: 0.6632 - accuracy: 0.7822
测试损失: 0.6631759405136108
测试精度: 0.7821999788284302

Process finished with exit code 0
